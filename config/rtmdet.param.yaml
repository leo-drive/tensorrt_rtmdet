/**:
  ros__parameters:
    # publish debug image, including bounding box, class name, mask
    is_publish_debug_image: true

    model_path: "$(var data_path)/tensorrt_rtmdet/$(var model_name).onnx"
    color_map_path: "$(var data_path)/tensorrt_rtmdet/color_map.csv"
    plugin_paths: [ "./build/tensorrt_rtmdet/libtensorrt_rtmdet_plugin.so" ]
    mean: [ 103.53, 116.28, 123.675 ]
    std: [ 57.375, 57.12, 58.395 ]
    number_classes: 80
    score_threshold: 0.3
    nms_threshold: 0.3
    mask_threshold: 0.8
    precision: "fp16" # Operation precision to be used on inference. Valid value is one of: [fp32, fp16, int8].
    calibration_algorithm: "MinMax" # Calibration algorithm to be used for quantization when precision==int8. Valid value is one of: [Entropy, (Legacy | Percentile), MinMax].
    dla_core_id: -1 # If positive ID value is specified, the node assign inference task to the DLA core.
    quantize_first_layer: false # If true, set the operating precision for the first (input) layer to be fp16. This option is valid only when precision==int8.
    quantize_last_layer: false # If true, set the operating precision for the last (output) layer to be fp16. This option is valid only when precision==int8.
    profile_per_layer: false # If true, profiler function will be enabled. Since the profile function may affect execution speed, it is recommended to set this flag true only for development purpose.
    clip_value: 6.0 # If positive value is specified, the value of each layer output will be clipped between [0.0, clip_value]. This option is valid only when precision==int8 and used to manually specify the dynamic range instead of using any calibration.
    preprocess_on_gpu: true # If true, pre-processing is performed on GPU.
    calibration_image_list_path: "" # Path to a file which contains path to images. Those images will be used for int8 quantization.